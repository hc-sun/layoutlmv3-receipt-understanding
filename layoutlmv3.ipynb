{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayoutLMv3 for receipt information understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Fine Tuning the LayoutLMv3 for CORD Dataset](#fine-tuning-the-layoutlmv3-for-cord-dataset)\n",
    "2. [Load the Fine Tuned Model for Test Dataset](#load-the-fine-tuned-model-for-test-dataset)\n",
    "3. [Detect total amount in a New Receipt Dataset](#detect-total-amount-in-a-new-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning the LayoutLMv3 for CORD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor\n",
    "from datasets.features import ClassLabel\n",
    "from datasets import Features, Sequence, Value, Array2D, Array3D\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "from transformers import LayoutLMv3ForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers.data.data_collator import default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from huggingface\n",
    "dataset = load_dataset(\"hcsun/cord\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'words', 'bboxes', 'ner_tags', 'image'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'words', 'bboxes', 'ner_tags', 'image'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'words', 'bboxes', 'ner_tags', 'image'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessed dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'words': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'bboxes': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-MENU.NM', 'B-MENU.NUM', 'B-MENU.UNITPRICE', 'B-MENU.CNT', 'B-MENU.DISCOUNTPRICE', 'B-MENU.PRICE', 'B-MENU.ITEMSUBTOTAL', 'B-MENU.VATYN', 'B-MENU.ETC', 'B-MENU.SUB_NM', 'B-MENU.SUB_UNITPRICE', 'B-MENU.SUB_CNT', 'B-MENU.SUB_PRICE', 'B-MENU.SUB_ETC', 'B-VOID_MENU.NM', 'B-VOID_MENU.PRICE', 'B-SUB_TOTAL.SUBTOTAL_PRICE', 'B-SUB_TOTAL.DISCOUNT_PRICE', 'B-SUB_TOTAL.SERVICE_PRICE', 'B-SUB_TOTAL.OTHERSVC_PRICE', 'B-SUB_TOTAL.TAX_PRICE', 'B-SUB_TOTAL.ETC', 'B-TOTAL.TOTAL_PRICE', 'B-TOTAL.TOTAL_ETC', 'B-TOTAL.CASHPRICE', 'B-TOTAL.CHANGEPRICE', 'B-TOTAL.CREDITCARDPRICE', 'B-TOTAL.EMONEYPRICE', 'B-TOTAL.MENUTYPE_CNT', 'B-TOTAL.MENUQTY_CNT', 'I-MENU.NM', 'I-MENU.NUM', 'I-MENU.UNITPRICE', 'I-MENU.CNT', 'I-MENU.DISCOUNTPRICE', 'I-MENU.PRICE', 'I-MENU.ITEMSUBTOTAL', 'I-MENU.VATYN', 'I-MENU.ETC', 'I-MENU.SUB_NM', 'I-MENU.SUB_UNITPRICE', 'I-MENU.SUB_CNT', 'I-MENU.SUB_PRICE', 'I-MENU.SUB_ETC', 'I-VOID_MENU.NM', 'I-VOID_MENU.PRICE', 'I-SUB_TOTAL.SUBTOTAL_PRICE', 'I-SUB_TOTAL.DISCOUNT_PRICE', 'I-SUB_TOTAL.SERVICE_PRICE', 'I-SUB_TOTAL.OTHERSVC_PRICE', 'I-SUB_TOTAL.TAX_PRICE', 'I-SUB_TOTAL.ETC', 'I-TOTAL.TOTAL_PRICE', 'I-TOTAL.TOTAL_ETC', 'I-TOTAL.CASHPRICE', 'I-TOTAL.CHANGEPRICE', 'I-TOTAL.CREDITCARDPRICE', 'I-TOTAL.EMONEYPRICE', 'I-TOTAL.MENUTYPE_CNT', 'I-TOTAL.MENUQTY_CNT'], id=None), length=-1, id=None),\n",
       " 'image': Image(mode=None, decode=True, id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noah\\miniconda3\\envs\\llm\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the layoutlmv3 processor\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for NER task and create mappings between label names and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features\n",
    "features = dataset[\"train\"].features\n",
    "label_column_name = \"ner_tags\"\n",
    "\n",
    "def get_label_list(labels):\n",
    "    \"\"\"Function to get a list of unique labels from the dataset.\"\"\"\n",
    "    return sorted(set(label for sublist in labels for label in sublist))\n",
    "\n",
    "# Get the label list\n",
    "if isinstance(features[label_column_name].feature, ClassLabel):\n",
    "    label_list = features[label_column_name].feature.names\n",
    "else:\n",
    "    label_list = get_label_list(dataset[\"train\"][label_column_name])\n",
    "\n",
    "# Create mappings from label to id and vice versa\n",
    "id2label = {k: v for k,v in enumerate(label_list)}\n",
    "label2id = {v: k for k,v in enumerate(label_list)}\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-MENU.NM', 'B-MENU.NUM', 'B-MENU.UNITPRICE', 'B-MENU.CNT', 'B-MENU.DISCOUNTPRICE', 'B-MENU.PRICE', 'B-MENU.ITEMSUBTOTAL', 'B-MENU.VATYN', 'B-MENU.ETC', 'B-MENU.SUB_NM', 'B-MENU.SUB_UNITPRICE', 'B-MENU.SUB_CNT', 'B-MENU.SUB_PRICE', 'B-MENU.SUB_ETC', 'B-VOID_MENU.NM', 'B-VOID_MENU.PRICE', 'B-SUB_TOTAL.SUBTOTAL_PRICE', 'B-SUB_TOTAL.DISCOUNT_PRICE', 'B-SUB_TOTAL.SERVICE_PRICE', 'B-SUB_TOTAL.OTHERSVC_PRICE', 'B-SUB_TOTAL.TAX_PRICE', 'B-SUB_TOTAL.ETC', 'B-TOTAL.TOTAL_PRICE', 'B-TOTAL.TOTAL_ETC', 'B-TOTAL.CASHPRICE', 'B-TOTAL.CHANGEPRICE', 'B-TOTAL.CREDITCARDPRICE', 'B-TOTAL.EMONEYPRICE', 'B-TOTAL.MENUTYPE_CNT', 'B-TOTAL.MENUQTY_CNT', 'I-MENU.NM', 'I-MENU.NUM', 'I-MENU.UNITPRICE', 'I-MENU.CNT', 'I-MENU.DISCOUNTPRICE', 'I-MENU.PRICE', 'I-MENU.ITEMSUBTOTAL', 'I-MENU.VATYN', 'I-MENU.ETC', 'I-MENU.SUB_NM', 'I-MENU.SUB_UNITPRICE', 'I-MENU.SUB_CNT', 'I-MENU.SUB_PRICE', 'I-MENU.SUB_ETC', 'I-VOID_MENU.NM', 'I-VOID_MENU.PRICE', 'I-SUB_TOTAL.SUBTOTAL_PRICE', 'I-SUB_TOTAL.DISCOUNT_PRICE', 'I-SUB_TOTAL.SERVICE_PRICE', 'I-SUB_TOTAL.OTHERSVC_PRICE', 'I-SUB_TOTAL.TAX_PRICE', 'I-SUB_TOTAL.ETC', 'I-TOTAL.TOTAL_PRICE', 'I-TOTAL.TOTAL_ETC', 'I-TOTAL.CASHPRICE', 'I-TOTAL.CHANGEPRICE', 'I-TOTAL.CREDITCARDPRICE', 'I-TOTAL.EMONEYPRICE', 'I-TOTAL.MENUTYPE_CNT', 'I-TOTAL.MENUQTY_CNT']\n",
      "{0: 'O', 1: 'B-MENU.NM', 2: 'B-MENU.NUM', 3: 'B-MENU.UNITPRICE', 4: 'B-MENU.CNT', 5: 'B-MENU.DISCOUNTPRICE', 6: 'B-MENU.PRICE', 7: 'B-MENU.ITEMSUBTOTAL', 8: 'B-MENU.VATYN', 9: 'B-MENU.ETC', 10: 'B-MENU.SUB_NM', 11: 'B-MENU.SUB_UNITPRICE', 12: 'B-MENU.SUB_CNT', 13: 'B-MENU.SUB_PRICE', 14: 'B-MENU.SUB_ETC', 15: 'B-VOID_MENU.NM', 16: 'B-VOID_MENU.PRICE', 17: 'B-SUB_TOTAL.SUBTOTAL_PRICE', 18: 'B-SUB_TOTAL.DISCOUNT_PRICE', 19: 'B-SUB_TOTAL.SERVICE_PRICE', 20: 'B-SUB_TOTAL.OTHERSVC_PRICE', 21: 'B-SUB_TOTAL.TAX_PRICE', 22: 'B-SUB_TOTAL.ETC', 23: 'B-TOTAL.TOTAL_PRICE', 24: 'B-TOTAL.TOTAL_ETC', 25: 'B-TOTAL.CASHPRICE', 26: 'B-TOTAL.CHANGEPRICE', 27: 'B-TOTAL.CREDITCARDPRICE', 28: 'B-TOTAL.EMONEYPRICE', 29: 'B-TOTAL.MENUTYPE_CNT', 30: 'B-TOTAL.MENUQTY_CNT', 31: 'I-MENU.NM', 32: 'I-MENU.NUM', 33: 'I-MENU.UNITPRICE', 34: 'I-MENU.CNT', 35: 'I-MENU.DISCOUNTPRICE', 36: 'I-MENU.PRICE', 37: 'I-MENU.ITEMSUBTOTAL', 38: 'I-MENU.VATYN', 39: 'I-MENU.ETC', 40: 'I-MENU.SUB_NM', 41: 'I-MENU.SUB_UNITPRICE', 42: 'I-MENU.SUB_CNT', 43: 'I-MENU.SUB_PRICE', 44: 'I-MENU.SUB_ETC', 45: 'I-VOID_MENU.NM', 46: 'I-VOID_MENU.PRICE', 47: 'I-SUB_TOTAL.SUBTOTAL_PRICE', 48: 'I-SUB_TOTAL.DISCOUNT_PRICE', 49: 'I-SUB_TOTAL.SERVICE_PRICE', 50: 'I-SUB_TOTAL.OTHERSVC_PRICE', 51: 'I-SUB_TOTAL.TAX_PRICE', 52: 'I-SUB_TOTAL.ETC', 53: 'I-TOTAL.TOTAL_PRICE', 54: 'I-TOTAL.TOTAL_ETC', 55: 'I-TOTAL.CASHPRICE', 56: 'I-TOTAL.CHANGEPRICE', 57: 'I-TOTAL.CREDITCARDPRICE', 58: 'I-TOTAL.EMONEYPRICE', 59: 'I-TOTAL.MENUTYPE_CNT', 60: 'I-TOTAL.MENUQTY_CNT'}\n"
     ]
    }
   ],
   "source": [
    "print(label_list)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structure of the data that will be fed to the model\n",
    "features = Features({\n",
    "    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "    'input_ids': Sequence(feature=Value(dtype='int64')),\n",
    "    'attention_mask': Sequence(Value(dtype='int64')),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "    'labels': Sequence(feature=Value(dtype='int64')),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ddfc6fc9b04a88ae0527c55b9804ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c11cebf4e846f5b472bb8d268df245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_examples(examples):\n",
    "    \"\"\"Function to prepare examples for training. Encode the examples using the layoutlmv3 processor.\"\"\"\n",
    "    images = examples['image']\n",
    "    words = examples['words']\n",
    "    boxes = examples['bboxes']\n",
    "    word_labels = examples[label_column_name]\n",
    "    encoding = processor(images, words, boxes=boxes, word_labels=word_labels, truncation=True, padding=\"max_length\")\n",
    "    return encoding\n",
    "\n",
    "def prepare_dataset(dataset, batched=True, remove_columns=dataset[\"train\"].column_names, features=features):\n",
    "    \"\"\"Function to prepare the dataset for training. Map the prepare_examples function to each batch of examples in the dataset.\"\"\"\n",
    "    return dataset.map(\n",
    "        prepare_examples,\n",
    "        batched=batched,\n",
    "        remove_columns=remove_columns,\n",
    "        features=features,\n",
    "    )\n",
    "\n",
    "train_dataset = prepare_dataset(dataset[\"train\"])\n",
    "eval_dataset = prepare_dataset(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output format of the train_dataset to PyTorch tensors\n",
    "train_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d):\n",
    "    \"\"\"Function to flatten a dictionary.\"\"\"\n",
    "    def expand(key, value):\n",
    "        if isinstance(value, dict):\n",
    "            return [(key + '_' + k, v) for k, v in flatten_dict(value).items()]\n",
    "        else:\n",
    "            return [(key, value)]\n",
    "    items = [item for k, v in d.items() for item in expand(k, v)]\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\AppData\\Local\\Temp\\ipykernel_19108\\3597897577.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\", trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "# seqeval metric is used for sequence labeling evaluation\n",
    "metric = load_metric(\"seqeval\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p, return_entity_level_metrics=False):\n",
    "    \"\"\"Function to compute metrics for evaluation.\"\"\"\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [[label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [[label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        return flatten_dict(results)\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noah\\miniconda3\\envs\\llm\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained weights of the layoutlmv3 model, set the number of labels and the mappings from label to id\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\", id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b42ca0061c149cdbe632d7b33268ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Set up and start the training process for the model\n",
    "\n",
    "1. define the training arguments using the `TrainingArguments` class from the Hugging Face's `transformers` library. These arguments include the output directory, maximum steps, batch sizes, learning rate, evaluation strategy etc.\n",
    "\n",
    "2. initialize the `Trainer` with the model, the training arguments, the training and evaluation datasets, a function to compute metrics etc.\n",
    "\n",
    "3. call `trainer.train()` to start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd64edabc2274b879e1d563ab0705d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1415, 'learning_rate': 1.6040000000000002e-05, 'epoch': 1.25}\n",
      "{'loss': 0.961, 'learning_rate': 1.204e-05, 'epoch': 2.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2267fa87c0da49fbabe778d5e9cc5507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noah\\miniconda3\\envs\\llm\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5548838973045349, 'eval_precision': 0.8511730205278593, 'eval_recall': 0.8690119760479041, 'eval_f1': 0.86, 'eval_accuracy': 0.8730899830220713, 'eval_runtime': 10.7584, 'eval_samples_per_second': 9.295, 'eval_steps_per_second': 1.859, 'epoch': 3.12}\n",
      "{'loss': 0.5622, 'learning_rate': 8.040000000000001e-06, 'epoch': 3.75}\n",
      "{'loss': 0.4423, 'learning_rate': 4.04e-06, 'epoch': 5.0}\n",
      "{'loss': 0.3714, 'learning_rate': 4e-08, 'epoch': 6.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc78df50716490ba4080341d0f01c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3655731678009033, 'eval_precision': 0.8983050847457628, 'eval_recall': 0.9124251497005988, 'eval_f1': 0.9053100631266245, 'eval_accuracy': 0.9231748726655348, 'eval_runtime': 10.4896, 'eval_samples_per_second': 9.533, 'eval_steps_per_second': 1.907, 'epoch': 6.25}\n",
      "{'train_runtime': 4118.615, 'train_samples_per_second': 1.214, 'train_steps_per_second': 0.121, 'train_loss': 0.8956798400878906, 'epoch': 6.25}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.8956798400878906, metrics={'train_runtime': 4118.615, 'train_samples_per_second': 1.214, 'train_steps_per_second': 0.121, 'train_loss': 0.8956798400878906, 'epoch': 6.25})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"layoutlmv3-cord\",\n",
    "    max_steps=500,\n",
    "    per_device_train_batch_size=5,\n",
    "    per_device_eval_batch_size=5,\n",
    "    push_to_hub=True,\n",
    "    push_to_hub_model_id=f\"layoutlmv3-cord\",\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    gradient_accumulation_steps=2,\n",
    "    fp16=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=processor,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noah\\miniconda3\\envs\\llm\\lib\\site-packages\\transformers\\modeling_utils.py:993: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297c2d7859d24015bc622490ba2182a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noah\\miniconda3\\envs\\llm\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3655731678009033,\n",
       " 'eval_precision': 0.8983050847457628,\n",
       " 'eval_recall': 0.9124251497005988,\n",
       " 'eval_f1': 0.9053100631266245,\n",
       " 'eval_accuracy': 0.9231748726655348,\n",
       " 'eval_runtime': 10.8356,\n",
       " 'eval_samples_per_second': 9.229,\n",
       " 'eval_steps_per_second': 1.846,\n",
       " 'epoch': 6.25}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation Results with 500 steps of training\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model(r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
